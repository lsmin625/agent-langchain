{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# í”„ë¡¬í”„íŠ¸(ì‹œìŠ¤í…œ ì—­í•  ë©”ì‹œì§€)ë¥¼ í†µí•œ ì±—ë´‡ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI LLM ì¤€ë¹„ \n",
    "* í™˜ê²½ ë³€ìˆ˜(`.env` íŒŒì¼)ì—ì„œ API Key ë¡œë”©\n",
    "* ê°œë°œ í™˜ê²½ì—ì„œëŠ” `gpt-4o-mini` ë˜ëŠ” `gpt-3.5-turbo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "import gradio as gr\n",
    "\n",
    "# .env ë¡œë“œ ë° API í‚¤ í™•ì¸\n",
    "load_dotenv()\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì‹œìŠ¤í…œ ì—­í•  ë©”ì‹œì§€ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€\n",
    "system_message = SystemMessage(\n",
    "    content=\"ë‹¹ì‹ ì€ 'ëª…íƒì • ì½”ë‚œ' ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µí•´ ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "initial_messages = [system_message]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì±„íŒ… ì²˜ë¦¬ í•¨ìˆ˜ (`add_messages` ì‚¬ìš©)\n",
    "\n",
    "1. `add_messages(left, right)` (ë¦¬ìŠ¤íŠ¸ + ë¦¬ìŠ¤íŠ¸)\n",
    "    - `left` ë¦¬ìŠ¤íŠ¸ì˜ ë©”ì‹œì§€ë“¤ì„ ìš°ì„  ì €ì¥í•œ ë’¤, `right` ë¦¬ìŠ¤íŠ¸ì˜ ë©”ì‹œì§€ë“¤ë¡œ ë®ì–´ì“°ê¸° ë˜ëŠ” ì¶”ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    - IDê°€ ì¤‘ë³µëœ ë©”ì‹œì§€ëŠ” `right`ì˜ ë©”ì‹œì§€ë¡œ êµì²´(ë®ì–´ì“°ê¸°)ë˜ê³ , ìƒˆë¡œìš´ IDëŠ” ë¦¬ìŠ¤íŠ¸ ëì— ìˆœì„œëŒ€ë¡œ ì¶”ê°€ë©ë‹ˆë‹¤.\n",
    "\n",
    "2. `add_messages(state[\"messages\"], new_message)` (ë¦¬ìŠ¤íŠ¸ + ë‹¨ì¼ ë©”ì‹œì§€)\n",
    "    - ë‚´ë¶€ì ìœ¼ë¡œ ë‹¨ì¼ ë©”ì‹œì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ ë™ì¼í•œ ë¡œì§ì„ ì ìš©í•©ë‹ˆë‹¤.\n",
    "    - ê²°ê³¼ì ìœ¼ë¡œ ê¸°ì¡´ ë©”ì‹œì§€ ë’¤ì— ìƒˆë¡œìš´ ë©”ì‹œì§€ê°€ ì¶”ê°€ë©ë‹ˆë‹¤.\n",
    "\n",
    "â€» Gradioì™€ OpenAI APIì˜ ì¶œë ¥ í˜¸í™˜ `chat_display` í¬ë§· (`{\"role\": \"...\", \"content\": \"...\"}`)\n",
    "- `role`ì€ 'user'ì™€ 'assistant'ë¡œ ì§€ì •ë˜ì–´ì•¼í•¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì±„íŒ… ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def chat_fn(user_input, chat_history):\n",
    "    if chat_history is None:\n",
    "        chat_history = initial_messages.copy()\n",
    "\n",
    "    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€\n",
    "    human_msg = HumanMessage(content=user_input)\n",
    "    chat_history = add_messages(chat_history, [human_msg])\n",
    "\n",
    "    # LLM ì‘ë‹µ ìƒì„± ë° ì¶”ê°€\n",
    "    ai_msg = llm.invoke(chat_history)\n",
    "    chat_history = add_messages(chat_history, [ai_msg])\n",
    "\n",
    "    # OpenAI ìŠ¤íƒ€ì¼ ë©”ì‹œì§€ë¡œ ë³€í™˜ (type=\"messages\" ëŒ€ì‘)\n",
    "    chat_display = []\n",
    "    for msg in chat_history:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            chat_display.append({\"role\": \"user\", \"content\": msg.content})\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            chat_display.append({\"role\": \"assistant\", \"content\": msg.content})\n",
    "\n",
    "    return chat_display, chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio ì¸í„°í˜ì´ìŠ¤ êµ¬ì„±\n",
    "\n",
    "íŒ¨í‚¤ì§€ ì„¤ì¹˜ `pip install gradio`\n",
    "\n",
    "Gradioì˜ Blocks UI êµ¬ì„± ë°©ì‹ì„ ì‚¬ìš©í•´ ëª…íƒì • ì½”ë‚œ í€´ì¦ˆ ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬ì„±\n",
    "- `with gr.Blocks() as demo `: Gradioì˜ ë ˆì´ì•„ì›ƒ ê¸°ë°˜ UI ë¸”ë¡ì„ ì‹œì‘ - ì•± ì „ì²´ ì¸ìŠ¤í„´ìŠ¤ë¥¼ `demo`ë¡œ ì„ ì–¸\n",
    "- `gr.Markdown(...)` : í™”ë©´ ìƒë‹¨ì— í‘œì‹œí•  ì„¤ëª… ë¬¸êµ¬ (Markdown ë¬¸ë²• ì‚¬ìš©)\n",
    "- `gr.Chatbot(...)` : ì‚¬ìš©ìì™€ AI ê°„ì˜ ëŒ€í™”ë¥¼ ë³´ì—¬ì£¼ëŠ” ëŒ€í™”ì°½ ì»´í¬ë„ŒíŠ¸\n",
    "- `gr.Textbox(...)` : ì‚¬ìš©ìê°€ ì…ë ¥í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ ì…ë ¥ì°½ (placeholderë¡œ ì…ë ¥ íŒíŠ¸ë¥¼ í‘œì‹œ)\n",
    "- `gr.State(initial_messages.copy())` : `initial_messages.copy()`ë¥¼ í˜¸ì¶œí•˜ì—¬ ì´ˆê¸° ìƒíƒœë¥¼ ì €ì¥\n",
    "\n",
    "â€» ì…ë ¥ ì²˜ë¦¬ ìƒì„¸ ì„¤ëª…\n",
    "\n",
    "1. `txt.submit(chat_fn, inputs=[txt, state], outputs=[chatbot, state])`\n",
    "    - `txt.submit(...)` : ì‚¬ìš©ìê°€ í…ìŠ¤íŠ¸ë°•ìŠ¤ì— ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ë©´ ì‹¤í–‰\n",
    "    - `chat_fn` : ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ - ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë°›ì•„ ì±—ë´‡ ì‘ë‹µê³¼ ìƒíƒœë¥¼ ê³„ì‚° ë˜ëŠ” \n",
    "    - `inputs=[txt, state]` : í…ìŠ¤íŠ¸ ì…ë ¥ê°’ê³¼ ì´ì „ ìƒíƒœ(state)ë¥¼ chat_fnì— ì „ë‹¬\n",
    "    - `outputs=[chatbot, state]` : í•¨ìˆ˜ ê²°ê³¼ë¡œ ë‚˜ì˜¨ ëŒ€í™” ë‚´ìš©ê³¼ ìƒíƒœë¥¼ ì±—ë´‡ ì°½ê³¼ ë‚´ë¶€ ìƒíƒœì— ê°ê° ë°˜ì˜\n",
    "\n",
    "2. `txt.submit(lambda: \"\", None, txt)`\n",
    "    - `lambda: \"\"` : ì•„ë¬´ ë™ì‘ ì—†ì´ ë¹ˆ ë¬¸ìì—´ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜\n",
    "    - `None` : ì…ë ¥ê°’ì€ ì—†ìŒ\n",
    "    - `txt` : ì¶œë ¥ ëŒ€ìƒì€ í…ìŠ¤íŠ¸ë°•ìŠ¤ ìì‹  - ì…ë ¥ í›„ ìë™ìœ¼ë¡œ ì…ë ¥ì°½ì„ ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### ğŸ•µï¸â€â™‚ï¸ ëª…íƒì • ì½”ë‚œ ì „ë¬¸ê°€ì—ê²Œ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!\")\n",
    "\n",
    "    chatbot = gr.Chatbot(height=300, type=\"messages\", label=\"ëª…íƒì • ì½”ë‚œ ì „ë¬¸ê°€ ì±—ë´‡\")\n",
    "    txt = gr.Textbox(placeholder=\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...\", show_label=False)\n",
    "    state = gr.State(initial_messages.copy())\n",
    "\n",
    "    txt.submit(chat_fn, inputs=[txt, state], outputs=[chatbot, state])\n",
    "    txt.submit(lambda: \"\", None, txt)  # ì…ë ¥ì°½ ì´ˆê¸°í™”\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-t0JhnSEV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
