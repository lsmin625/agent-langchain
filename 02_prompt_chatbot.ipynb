{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# í”„ë¡¬í”„íŠ¸(ì‹œìŠ¤í…œ ì—­í•  ë©”ì‹œì§€)ë¥¼ í†µí•œ ì±—ë´‡ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI LLM ì¤€ë¹„ \n",
    "* í™˜ê²½ ë³€ìˆ˜(`.env` íŒŒì¼)ì—ì„œ API Key ë¡œë”©\n",
    "* ê°œë°œ í™˜ê²½ì—ì„œëŠ” `gpt-4o-mini` ë˜ëŠ” `gpt-3.5-turbo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "import gradio as gr\n",
    "\n",
    "# .env ë¡œë“œ ë° API í‚¤ í™•ì¸\n",
    "load_dotenv()\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì´ˆê¸° ë©”ì‹œì§€ - ì‹œìŠ¤í…œ ì—­í•  ë©”ì‹œì§€ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€\n",
    "initial_messages = [\n",
    "    SystemMessage(content=\"ë‹¹ì‹ ì€ 'ëª…íƒì • ì½”ë‚œ' ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µí•´ ì£¼ì„¸ìš”.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì±„íŒ… ì²˜ë¦¬ í•¨ìˆ˜\n",
    "Gradio UIì™€ ì—°ë™í•˜ëŠ” ì¸í„°í˜ì´ìŠ¤ í•¨ìˆ˜\n",
    "* `convert_history_to_display` : ì±„íŒ… ê¸°ë¡ì„ Gradio UI ì¶œë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜\n",
    "    - ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì •ë³´(`HumanMessage`)ì™€ LLMì˜ ì‘ë‹µ(`AIMessage`)ì¸ ê²½ìš° ì±„íŒ… ì¶œë ¥(`chat_display`)ì— ì¶”ê°€ \n",
    "    - ì´ˆê¸° ë©”ì‹œì§€ì— ì„¤ì •ëœ ì‹œìŠ¤í…œ ë©”ì‹œì§€(`SystemMessage`)ëŠ” ì¶œë ¥ë˜ì§€ ì•ŠìŒ\n",
    "\n",
    "* `chat_fn` : UI ì±„íŒ… ì²˜ë¦¬ í•¨ìˆ˜\n",
    "    - UI ì…ë ¥ì°½ì—ì„œ ì—”í„° ì´ë²¤íŠ¸(`txt.submit(chat_fn, inputs=[txt, state], outputs=[chatbot, state])`)ê°€ ë°œìƒ í•˜ë©´ í˜¸ì¶œë¨ \n",
    "    - ì±„íŒ… ì¶œë ¥(`chat_display`)ì˜ í¬ë§·(`{\"role\": \"...\", \"content\": \"...\"}`)ì—ì„œ `role`ì€ **'user'** ì™€ **'assistant'**'ë¡œ ì§€ì •ë˜ì–´ì•¼í•¨.\n",
    "\n",
    "* `yield`\n",
    "    - Pythonì—ì„œ í•¨ìˆ˜ë¥¼ íŠ¹ë³„í•œ ì¢…ë¥˜ì˜ ì´í„°ë ˆì´í„°(iterator)ì¸ ì œë„ˆë ˆì´í„°(generator)ë¡œ ë§Œë“¤ì–´ì£¼ëŠ” í‚¤ì›Œë“œ\n",
    "    - ì¼ë°˜ì ì¸ í•¨ìˆ˜ê°€ returnìœ¼ë¡œ ê°’ì„ ë°˜í™˜í•˜ë©´ì„œ ì¢…ë£Œë˜ëŠ” ë°˜ë©´, yieldë¥¼ ì‚¬ìš©í•œ í•¨ìˆ˜ëŠ” ê°’ì„ í•´ë‹¹ ì‹œì ì— ê°’ì„ ë°˜í™˜ í›„ ìƒíƒœë¥¼ ìœ ì§€í•œ ì±„ ì ì‹œ ë©ˆì·„ë‹¤ê°€, ë‹¤ìŒ ìš”ì²­ì´ ì˜¤ë©´ ë©ˆì¶˜ ì§€ì ë¶€í„° ì‹¤í–‰ì„ ì¬ê°œ\n",
    "    - ëª¨ë“  ê²°ê³¼ë¥¼ í•œ ë²ˆì— ê³„ì‚°í•´ì„œ ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ëŠ” ëŒ€ì‹ , í•„ìš”í•œ ì‹œì ì— ê°’ì„ í•˜ë‚˜ì”© ìƒì„± - **ì§€ì—° í‰ê°€(Lazy Evaluation)**\n",
    "    - `txt.submit` ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆì— ì˜í•´ ì œë„ˆë ˆì´í„°ì˜ ë‹¤ìŒ ìˆœì„œë¥¼ ì‹¤í–‰(`next()`ê°€ í˜¸ì¶œ)í•˜ê²Œ ë¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì±„íŒ… ê¸°ë¡ì„ UI ì¶œë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜\n",
    "def convert_history_to_display(history):\n",
    "    chat_display = []\n",
    "    for msg in history:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            chat_display.append({\"role\": \"user\", \"content\": msg.content})\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            chat_display.append({\"role\": \"assistant\", \"content\": msg.content})\n",
    "    return chat_display\n",
    "\n",
    "# ì±„íŒ… ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def chat_fn(user_input, chat_history):\n",
    "    human_message = HumanMessage(content=user_input)\n",
    "    chat_history.append(human_message)\n",
    "\n",
    "    working_display = convert_history_to_display(chat_history)\n",
    "    working_display.append({\"role\": \"assistant\", \"content\": \"ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... ğŸ¤”\"})\n",
    "    yield working_display, chat_history\n",
    "\n",
    "    ai_message = llm.invoke(chat_history)\n",
    "    chat_history.append(ai_message)\n",
    "\n",
    "    # 5. ìµœì¢… ì±„íŒ… ê¸°ë¡ìœ¼ë¡œ UIì¶œë ¥\n",
    "    final_display = convert_history_to_display(chat_history)\n",
    "    yield final_display, chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio ì¸í„°í˜ì´ìŠ¤ êµ¬ì„±\n",
    "\n",
    "íŒ¨í‚¤ì§€ ì„¤ì¹˜ `pip install gradio`\n",
    "\n",
    "Gradioì˜ Blocks UI êµ¬ì„± ë°©ì‹ì„ ì‚¬ìš©í•´ ëª…íƒì • ì½”ë‚œ í€´ì¦ˆ ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬ì„±\n",
    "- `with gr.Blocks() as demo `: Gradioì˜ ë ˆì´ì•„ì›ƒ ê¸°ë°˜ UI ë¸”ë¡ì„ ì‹œì‘ - ì•± ì „ì²´ ì¸ìŠ¤í„´ìŠ¤ë¥¼ `demo`ë¡œ ì„ ì–¸\n",
    "- `gr.Markdown(...)` : í™”ë©´ ìƒë‹¨ì— í‘œì‹œí•  ì„¤ëª… ë¬¸êµ¬ (Markdown ë¬¸ë²• ì‚¬ìš©)\n",
    "- `gr.Chatbot(...)` : ì‚¬ìš©ìì™€ AI ê°„ì˜ ëŒ€í™”ë¥¼ ë³´ì—¬ì£¼ëŠ” ëŒ€í™”ì°½ ì»´í¬ë„ŒíŠ¸\n",
    "- `gr.Textbox(...)` : ì‚¬ìš©ìê°€ ì…ë ¥í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ ì…ë ¥ì°½ (placeholderë¡œ ì…ë ¥ íŒíŠ¸ë¥¼ í‘œì‹œ)\n",
    "- `gr.State(initial_messages.copy())` : `initial_messages.copy()`ë¥¼ í˜¸ì¶œí•˜ì—¬ ì´ˆê¸° ìƒíƒœë¥¼ ì €ì¥\n",
    "\n",
    "â€» ì…ë ¥ ì²˜ë¦¬ ìƒì„¸ ì„¤ëª…\n",
    "\n",
    "1. `txt.submit(chat_fn, inputs=[txt, state], outputs=[chatbot, state])`\n",
    "    - `txt.submit(...)` : ì‚¬ìš©ìê°€ í…ìŠ¤íŠ¸ë°•ìŠ¤ì— ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ë©´ ì‹¤í–‰\n",
    "    - `chat_fn` : ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ - ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë°›ì•„ ì±—ë´‡ ì‘ë‹µê³¼ ìƒíƒœë¥¼ ê³„ì‚° ë˜ëŠ” \n",
    "    - `inputs=[txt, state]` : í…ìŠ¤íŠ¸ ì…ë ¥ê°’ê³¼ ì´ì „ ìƒíƒœ(state)ë¥¼ chat_fnì— ì „ë‹¬\n",
    "    - `outputs=[chatbot, state]` : í•¨ìˆ˜ ê²°ê³¼ë¡œ ë‚˜ì˜¨ ëŒ€í™” ë‚´ìš©ê³¼ ìƒíƒœë¥¼ ì±—ë´‡ ì°½ê³¼ ë‚´ë¶€ ìƒíƒœì— ê°ê° ë°˜ì˜\n",
    "\n",
    "2. `txt.submit(lambda: \"\", None, txt)`\n",
    "    - `lambda: \"\"` : ì•„ë¬´ ë™ì‘ ì—†ì´ ë¹ˆ ë¬¸ìì—´ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜\n",
    "    - `None` : ì…ë ¥ê°’ì€ ì—†ìŒ\n",
    "    - `txt` : ì¶œë ¥ ëŒ€ìƒì€ í…ìŠ¤íŠ¸ë°•ìŠ¤ ìì‹  - ì…ë ¥ í›„ ìë™ìœ¼ë¡œ ì…ë ¥ì°½ì„ ì´ˆê¸°í™”\n",
    "\n",
    "â€» ëŒë‹¤(`lambda`) í•¨ìˆ˜ëŠ” ì´ë¦„ ì—†ì´ ê°„ë‹¨í•˜ê²Œ ì‚¬ìš©í•˜ëŠ” **í•œ ì¤„ì§œë¦¬ ìµëª… í•¨ìˆ˜(anonymous function)** - ì„ì‹œë¡œ ì‚¬ìš©í•  ê°„ë‹¨í•œ ê¸°ëŠ¥ì´ í•„ìš”í•  ë•Œ êµ¬í˜„\n",
    "\n",
    "```python\n",
    "lambda ë§¤ê°œë³€ìˆ˜1, ë§¤ê°œë³€ìˆ˜2, ... : í‘œí˜„ì‹\n",
    "\n",
    "# ì§ìˆ˜ë§Œ ê±¸ëŸ¬ë‚´ê³  ì‹¶ì„ ë•Œ\n",
    "numbers = [1, 2, 3, 4, 5, 6]\n",
    "even_numbers = list(filter(lambda x: x % 2 == 0, numbers)) # [2, 4, 6]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### ğŸ•µï¸â€â™‚ï¸ ëª…íƒì • ì½”ë‚œ ì „ë¬¸ê°€ì—ê²Œ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!\")\n",
    "\n",
    "    chatbot = gr.Chatbot(height=300, type=\"messages\", label=\"ëª…íƒì • ì½”ë‚œ ì „ë¬¸ê°€ ì±—ë´‡\")\n",
    "    txt = gr.Textbox(placeholder=\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...\", show_label=False)\n",
    "    state = gr.State(initial_messages.copy())\n",
    "\n",
    "    txt.submit(chat_fn, inputs=[txt, state], outputs=[chatbot, state])\n",
    "    txt.submit(lambda: \"\", None, txt)  # ì…ë ¥ì°½ ì´ˆê¸°í™”\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-t0JhnSEV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
