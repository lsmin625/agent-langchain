{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain í”„ë¡¬í”„íŠ¸ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI LLM ì¤€ë¹„ \n",
    "* í™˜ê²½ ë³€ìˆ˜(`.env` íŒŒì¼)ì—ì„œ API Key ë¡œë”©\n",
    "* ê°œë°œ í™˜ê²½ì—ì„œëŠ” `gpt-4o-mini` ë˜ëŠ” `gpt-3.5-turbo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "import gradio as gr\n",
    "\n",
    "# .env ë¡œë“œ ë° API í‚¤ í™•ì¸\n",
    "load_dotenv()\n",
    "print(f\"{os.getenv('OPENAI_API_KEY')[:9]}***\")  # ë”°ì˜´í‘œ ì¤‘ì²© ë¬¸ì œ í•´ê²°\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "print(f\"LLM ëª¨ë¸: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì‹œìŠ¤í…œ ì—­í•  ë©”ì‹œì§€ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€\n",
    "system_message = SystemMessage(\n",
    "    content=\"ë‹¹ì‹ ì€ 'ëª…íƒì • ì½”ë‚œ' ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µí•´ ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "initial_messages = [system_message]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì±„íŒ… ì²˜ë¦¬ í•¨ìˆ˜ (`add_messages` ì‚¬ìš©)\n",
    "\n",
    "1. `add_messages(left, right)` (ë¦¬ìŠ¤íŠ¸ + ë¦¬ìŠ¤íŠ¸)\n",
    "    - `left` ë¦¬ìŠ¤íŠ¸ì˜ ë©”ì‹œì§€ë“¤ì„ ìš°ì„  ì €ì¥í•œ ë’¤, `right` ë¦¬ìŠ¤íŠ¸ì˜ ë©”ì‹œì§€ë“¤ë¡œ ë®ì–´ì“°ê¸° ë˜ëŠ” ì¶”ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    - IDê°€ ì¤‘ë³µëœ ë©”ì‹œì§€ëŠ” `right`ì˜ ë©”ì‹œì§€ë¡œ êµì²´(ë®ì–´ì“°ê¸°)ë˜ê³ , ìƒˆë¡œìš´ IDëŠ” ë¦¬ìŠ¤íŠ¸ ëì— ìˆœì„œëŒ€ë¡œ ì¶”ê°€ë©ë‹ˆë‹¤.\n",
    "\n",
    "2. `add_messages(state[\"messages\"], new_message)` (ë¦¬ìŠ¤íŠ¸ + ë‹¨ì¼ ë©”ì‹œì§€)\n",
    "    - ë‚´ë¶€ì ìœ¼ë¡œ ë‹¨ì¼ ë©”ì‹œì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ ë™ì¼í•œ ë¡œì§ì„ ì ìš©í•©ë‹ˆë‹¤.\n",
    "    - ê²°ê³¼ì ìœ¼ë¡œ ê¸°ì¡´ ë©”ì‹œì§€ ë’¤ì— ìƒˆë¡œìš´ ë©”ì‹œì§€ê°€ ì¶”ê°€ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì±„íŒ… ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def chat_fn(user_input, chat_history):\n",
    "    if chat_history is None:\n",
    "        chat_history = initial_messages.copy()\n",
    "\n",
    "    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€\n",
    "    human_msg = HumanMessage(content=user_input)\n",
    "    chat_history = add_messages(chat_history, [human_msg])\n",
    "\n",
    "    # LLM ì‘ë‹µ ìƒì„± ë° ì¶”ê°€\n",
    "    ai_msg = llm.invoke(chat_history)\n",
    "    chat_history = add_messages(chat_history, [ai_msg])\n",
    "\n",
    "    # OpenAI ìŠ¤íƒ€ì¼ ë©”ì‹œì§€ë¡œ ë³€í™˜ (type=\"messages\" ëŒ€ì‘)\n",
    "    chat_display = []\n",
    "    for msg in chat_history:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            chat_display.append({\"role\": \"user\", \"content\": msg.content})\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            chat_display.append({\"role\": \"assistant\", \"content\": msg.content})\n",
    "\n",
    "    return chat_display, chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradio ì¸í„°í˜ì´ìŠ¤ êµ¬ì„±\n",
    "íŒ¨í‚¤ì§€ ì„¤ì¹˜ `pip install gradio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### ğŸ•µï¸â€â™‚ï¸ ëª…íƒì • ì½”ë‚œ ì „ë¬¸ê°€ì—ê²Œ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!\")\n",
    "\n",
    "    chatbot = gr.Chatbot(height=300, type=\"messages\", label=\"ëª…íƒì • ì½”ë‚œ ì „ë¬¸ê°€ ì±—ë´‡\")\n",
    "    txt = gr.Textbox(placeholder=\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...\", show_label=False)\n",
    "    state = gr.State(initial_messages.copy())\n",
    "\n",
    "    txt.submit(chat_fn, inputs=[txt, state], outputs=[chatbot, state])\n",
    "    txt.submit(lambda: \"\", None, txt)  # ì…ë ¥ì°½ ì´ˆê¸°í™”\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-t0JhnSEV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
