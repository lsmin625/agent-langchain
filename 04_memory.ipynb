{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain 프롬프트 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI LLM 준비 \n",
    "* 환경 변수(`.env` 파일)에서 API Key 로딩\n",
    "* 개발 환경에서는 `gpt-4o-mini` 또는 `gpt-3.5-turbo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-x***\n",
      "gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "print(f\"{os.getenv(\"OPENAI_API_KEY\")[:9]}***\")\n",
    "\n",
    "# OpenAI LLM 준비\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "print(llm.model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 역할 기반 메시지 구성\n",
    "| 역할 (Role)       | 클래스명                              | 설명                                              |\n",
    "| --------------- | --------------------------------- | ----------------------------------------------- |\n",
    "| system          | `SystemMessage`                   | 모델의 행동 지침이나 문맥을 설정하는 초기 메시지                     |\n",
    "| user            | `HumanMessage`                    | 사용자의 입력을 나타냄 (사람이 입력한 메시지)                      |\n",
    "| assistant       | `AIMessage`                       | LLM의 응답을 나타냄                                    |\n",
    "| function/tool   | `FunctionMessage` / `ToolMessage` | 도구 실행 결과나 함수 응답을 나타냄 (OpenAI tool 사용 시)         |\n",
    "| generic (역할 없음) | `ChatMessage`                     | 역할을 문자열로 직접 지정하여 유연하게 사용 (예: \"critic\", \"coach\") |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content=\"당신은 '명탐정 코난' 전문가입니다. 질문에 친절하고 정확하게 답해 주세요.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='코난이 작아진 이유가 뭐죠?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"당신은 '명탐정 코난' 전문가입니다. 질문에 친절하고 정확하게 답해 주세요.\"),\n",
    "    HumanMessage(content=\"코난이 작아진 이유가 뭐죠?\")\n",
    "]\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM으로 역할 기반 메시지 주고 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 응답:\n",
      "코난이 작아진 이유는 주인공 신이치 코곤이 독극물인 \"APTX 4869\"을 복용했기 때문입니다. 이 약물은 그를 어린아이의 모습으로 변화시켰고, 이후 그는 '코난'이라는 이름으로 활동하게 됩니다. 코난은 사건을 해결하기 위해 원래의 모습으로 돌아가고자 하며, 그의 친구들과 함께 다양한 사건을 해결해 나가는 이야기가 전개됩니다.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(messages)\n",
    "\n",
    "# 응답 출력\n",
    "print(\">> 응답:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프롬프트(`ChatPromptTemplate`) 활용 메시지 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content=\"당신은 '명탐정 코난' 전문가입니다. 질문에 친절하고 정확하게 답해 주세요.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='블랙 조직의 리더는 누구인가요?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 '명탐정 코난' 전문가입니다. 질문에 친절하고 정확하게 답해 주세요.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "prompt_messages = chat_template.format_messages(\n",
    "    question=\"블랙 조직의 리더는 누구인가요?\"\n",
    ")\n",
    "\n",
    "print(prompt_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM으로 프롬프트 메시지 주고 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 응답:\n",
      "블랙 조직의 리더는 '짐'입니다. 그는 '블랙 조직'의 수장으로, 그 정체는 처음에는 베일에 싸여 있었지만, 이야기의 진행에 따라 그의 진짜 모습이 드러납니다. 짐은 냉철하고 잔인한 성격을 가지고 있으며, 조직의 다양한 범죄 활동을 지휘하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(prompt_messages)\n",
    "\n",
    "# 응답 출력\n",
    "print(\">> 응답:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-t0JhnSEV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
