{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 용의자 대화 녹음기 (메모리)\n",
    "\n",
    "- 사용자가 입력한 정보는 LLM에 전달하여 답변을 받아 오고 UI 채팅창을 통해 출력된다.\n",
    "- 사용자가 **\"기록 시작\" , \"녹음 시작\"** 지시를 하면 이후의 대화 내용은 기억하고, 그 이전의 내용은 기억하지 않는다.\n",
    "- 사용자가 **\"기록 중지\" , \"녹음 중지\"** 지시를 하면 그 이후의 내용은 기억하지 않는다.\n",
    "- 사용자가 **\"기록 삭제\" , \"녹음 삭제\"** 지시를 하면 모든 내용은 삭제한다.\n",
    "- Gradio UI를 통해 녹음기의 상태를 표시한다.\n",
    "- memory는 현재 세션에서만 캐시 형태로 사용될 수 있도록 관리한다.\n",
    "\n",
    "**※ 대화 기록이 있는 경우, 기록이 없는 경우에 대화 요약을 요청하여 결과를 비교한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정 및 OpenAI LLM 준비 \n",
    "* 환경 변수(`.env` 파일)에서 API Key 로딩\n",
    "* 개발 환경에서는 `gpt-4o-mini` 또는 `gpt-3.5-turbo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from typing import List, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain.tools import tool\n",
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI LLM 준비\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상태 관리 (메모리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AppState(BaseModel):\n",
    "    \"\"\"대화 목록과 기록 상태를 저장하는 모델\"\"\"\n",
    "    is_recording: bool = False\n",
    "    memory: List[HumanMessage | AIMessage] = Field(description=\"사용자와 AI의 대화 목록\", default_factory=list)\n",
    "\n",
    "    def get_status(self) -> str:\n",
    "        \"\"\"현재 기록 상태를 문자열로 반환\"\"\"\n",
    "        return \"🔴 기록 중\" if self.is_recording else \"⚫️ 기록 대기\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 메모리 관리 도구 (tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def start_memory_recording(state: AppState) -> str:\n",
    "    \"\"\"사용자가 대화 기록 시작을 요청할 때 이 도구를 호출합니다. '기록 시작', '녹음 시작' 등의 명령어에 해당합니다.\"\"\"\n",
    "    state.is_recording = True\n",
    "    return \"지금부터 대화를 기록하기 시작합니다.\"\n",
    "\n",
    "@tool\n",
    "def stop_memory_recording(state: AppState) -> str:\n",
    "    \"\"\"사용자가 대화 기록 중지를 요청할 때 이 도구를 호출합니다. '기록 중지', '녹음 중지' 등의 명령어에 해당합니다.\"\"\"\n",
    "    state.is_recording = False\n",
    "    return \"지금부터 대화를 기록하지 않습니다.\"\n",
    "\n",
    "@tool\n",
    "def clear_all_memory(state: AppState) -> str:\n",
    "    \"\"\"사용자가 모든 대화 기록 삭제를 요청할 때 이 도구를 호출합니다. '기록 삭제', '녹음 삭제' 등의 명령어에 해당합니다.\"\"\"\n",
    "    state.memory.clear()\n",
    "    return \"모든 대화 기록을 삭제했습니다.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프롬프트 구성\n",
    "1. `system_prompt`: 프롬프트 템플릿(`ChatPromptTemplate`)에 고정적으로 포함된 부분 - AI의 역할이나 행동 지침을 정의하는 정적인 텍스트로, 대화가 진행되어도 변하지 않음.\n",
    "\n",
    "2. chat_history (state.memory): `MessagesPlaceholder를` 통해 동적으로 채워지는 대화 기록 - `clear_all_memory` 함수는 바로 이 state.memory 리스트의 내용만 삭제.\n",
    "\n",
    "* 따라서 '기록 삭제' 명령을 실행하면 state.memory 리스트는 비워지지만, system_prompt는 프롬프트 템플릿 구조의 일부로서 그대로 유지 - 이후 새로운 대화를 시작할 때도 시스템 프롬프트는 항상 LLM에 전달됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "당신은 명탐정 코난의 수사하는 사건의 유력한 용의자 입니다.\n",
    "탐정의 질문에 적절하게 답변을 해야 합니다.\n",
    "탐정은 대화 기록을 관리하는 녹음기를 사용할 수 있습니다.: 'start_memory_recording', 'stop_memory_recording', 'clear_all_memory'.\n",
    "사용자의 요청을 분석해서 적절한 도구를 사용할 수 있도록 허용해 주어야 합니다.\n",
    "예를 들어, 사용자가 '녹음을 시작합니다.' 라고 말하면 'start_memory_recording' 도구를 호출해야 합니다.\n",
    "그 외 모든 일반적인 대화에는 도구를 사용하지 말고 직접 답변해야 하고 탐정에게 추가적인 질문을 해서는 안됩니다..\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCEL 파이프라인 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [start_memory_recording, stop_memory_recording, clear_all_memory]\n",
    "\n",
    "# 도구 이름을 키로, 함수를 값으로 하는 딕셔너리를 생성\n",
    "tool_map = {t.name: t for t in tools}\n",
    "\n",
    "# llm에 도구들을 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# LCEL 체인을 구성\n",
    "chain = prompt | llm_with_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UI 챗봇 인터페이스 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_fn(user_message: str, history: list, state: AppState):\n",
    "    response = chain.invoke({\"input\": user_message, \"chat_history\": state.memory})\n",
    "\n",
    "    ai_message = \"\"\n",
    "    # LLM 응답이 도구 호출일 경우\n",
    "    if response.tool_calls:\n",
    "        for tool_call in response.tool_calls:\n",
    "            tool_name = tool_call[\"name\"]\n",
    "            if tool_name in tool_map:\n",
    "                tool_to_call = tool_map[tool_name]\n",
    "                ai_message = tool_to_call.func(state=state)\n",
    "    else:\n",
    "        # 일반 메시지일 경우\n",
    "        ai_message = response.content\n",
    "\n",
    "    # history는 UI 표시용, state.memory는 LLM 전달용\n",
    "    history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    history.append({\"role\": \"assistant\", \"content\": ai_message})\n",
    "\n",
    "    # 기록 상태일 때만 실제 메모리에 대화 내용 추가\n",
    "    if state.is_recording:\n",
    "        # 도구 호출이 아닌 일반 대화만 메모리에 저장\n",
    "        if not response.tool_calls:\n",
    "            state.memory.extend(\n",
    "                [HumanMessage(content=user_message), AIMessage(content=ai_message)]\n",
    "            )\n",
    "\n",
    "    return history, state, state.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio UI 레이아웃 설계\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    initial_state = AppState()\n",
    "    state = gr.State(value=initial_state)\n",
    "\n",
    "    gr.Markdown(\"### 🕵️‍♂️ 탐정의 녹음기!\")\n",
    "    gr.Markdown(\"`기록 시작`, `기록 중지`, `기록 삭제` 명령어를 사용해 보세요.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        status_indicator = gr.Textbox(\n",
    "            value=initial_state.get_status(),\n",
    "            label=\"메모리 상태\",\n",
    "            interactive=False,\n",
    "        )\n",
    "\n",
    "    chatbot = gr.Chatbot(label=\"대화창\", height=300, type=\"messages\")\n",
    "\n",
    "    txt = gr.Textbox(placeholder=\"어제 저녁 9시에 어디에 계셨죠?\", show_label=False)\n",
    "    txt.submit(\n",
    "        chat_fn,\n",
    "        inputs=[txt, chatbot, state],\n",
    "        outputs=[chatbot, state, status_indicator]\n",
    "    )\n",
    "\n",
    "    # 입력창 초기화\n",
    "    txt.submit(lambda: \"\", None, txt)\n",
    "\n",
    "# 웹 서버 실행\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-t0JhnSEV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
