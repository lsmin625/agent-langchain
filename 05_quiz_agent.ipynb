{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ëª…íƒì • ì½”ë‚œ ë§¤ë‹ˆì•„ íŒë…ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI LLM ì¤€ë¹„ ë° í€´ì¦ˆ íŒŒì¼ ì§€ì •\n",
    "* í™˜ê²½ ë³€ìˆ˜(`.env` íŒŒì¼)ì—ì„œ API Key ë¡œë”©\n",
    "* ê°œë°œ í™˜ê²½ì—ì„œëŠ” `gpt-4o-mini` ë˜ëŠ” `gpt-3.5-turbo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import random, json, os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# í€´ì¦ˆ íŒŒì¼ ë° ì¶œì œ ë¬¸í•­ ê°œìˆ˜ ì§€ì •\n",
    "QUIZ_FILE = \"conan_quiz.json\"\n",
    "QUIZ_COUNT = 3\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### í€´ì¦ˆ ë¬¸í•­ (`conan_quiz.json`) ë¡œë”©\n",
    "- `def load_quiz()` :\tload_quizë¼ëŠ” ì´ë¦„ì˜ í•¨ìˆ˜ë¥¼ ì •ì˜\n",
    "- `with open(QUIZ_FILE, \"r\", encoding=\"utf-8\") as f`: ì§€ì •ëœ ê²½ë¡œì˜ JSON íŒŒì¼(QUIZ_FILE)ì„ UTF-8 ì¸ì½”ë”© ë°©ì‹ìœ¼ë¡œ ì½ê¸° ëª¨ë“œ(\"r\")ë¡œ ì—´ê³ , with êµ¬ë¬¸ì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ ì‚¬ìš© í›„ ìë™ìœ¼ë¡œ ë‹«íˆë„ë¡ ì²˜ë¦¬\n",
    "- `all_q = json.load(f)` : JSON íŒŒì¼ ë‚´ìš©ì„ íŒŒì‹±í•˜ì—¬ íŒŒì´ì¬ ê°ì²´(ë¦¬ìŠ¤íŠ¸ í˜•íƒœ, í€´ì¦ˆ ë¬¸ì œë“¤)ë¡œ ë³€í™˜.\n",
    "- `return random.sample(all_q, QUIZ_COUNT)` :ì „ì²´ ë¬¸ì œ ì¤‘ QUIZ_COUNT ê°œìˆ˜ë§Œí¼ ë¬´ì‘ìœ„ë¡œ ìƒ˜í”Œë§í•˜ì—¬ ë°˜í™˜(ì¤‘ë³µ ì—†ì´ ì„ íƒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ ë¡œë”© í•¨ìˆ˜\n",
    "def load_quiz():\n",
    "    with open(QUIZ_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        all_q = json.load(f)\n",
    "    return random.sample(all_q, QUIZ_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ ì¶œë ¥ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì œ ì¶œë ¥ - ì„ ë‹¤í˜• êµ¬ì„±\n",
    "def get_question(state):\n",
    "    idx = state[\"quiz_index\"]\n",
    "    q = state[\"questions\"][idx]\n",
    "    text = f\"ë¬¸ì œ {idx+1}: {q['question']}\"\n",
    "    if q[\"type\"] == \"multiple_choice\":\n",
    "        choices = [f\"{i+1}. {c}\" for i, c in enumerate(q[\"choices\"])]\n",
    "        text += \"\\n\" + \"\\n\".join(choices)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì‚¬ìš©ì ì‘ë‹µ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©ì ë‹µë³€ì„ ìƒíƒœì— ì €ì¥\n",
    "def update_state(state, user_input):\n",
    "    idx = state[\"quiz_index\"]\n",
    "    q = state[\"questions\"][idx]\n",
    "    processed = user_input.strip()\n",
    "\n",
    "    if q[\"type\"] == \"multiple_choice\":\n",
    "        try:\n",
    "            sel = int(processed) - 1\n",
    "            if 0 <= sel < len(q[\"choices\"]):\n",
    "                processed = q[\"choices\"][sel]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    state[\"user_answers\"].append(\n",
    "        {\n",
    "            \"question_text\": q[\"question\"],\n",
    "            \"user_response\": processed,\n",
    "            \"is_correct\": False,\n",
    "            \"correct_answer\": str(q[\"answer\"]),\n",
    "        }\n",
    "    )\n",
    "    state[\"quiz_index\"] += 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMìœ¼ë¡œ ë³´ë‚¼ ì±„ì  í”„ë¡¬í”„íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì±„ì  í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "def build_grading_prompt(state):\n",
    "    parts = [\n",
    "        \"ë‹¹ì‹ ì€ í€´ì¦ˆ ì±„ì ê´€ì…ë‹ˆë‹¤. ì‚¬ìš©ì ë‹µë³€ì„ ì •ë‹µ ì—¬ë¶€ë¡œ íŒë‹¨í•˜ê³  ê° ë¬¸ì œì— í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.\",\n",
    "        \"ë§ˆì§€ë§‰ì—ëŠ” 'ì´ì : X/Y' í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”.\",\n",
    "    ]\n",
    "    for i, (q, a) in enumerate(zip(state[\"questions\"], state[\"user_answers\"])):\n",
    "        parts.append(f\"\\në¬¸ì œ {i+1}: {q['question']}\")\n",
    "        if q[\"type\"] == \"multiple_choice\":\n",
    "            parts.append(f\"ì„ íƒì§€: {', '.join(q['choices'])}\")\n",
    "        parts.append(f\"ì •ë‹µ: {q['answer']}\")\n",
    "        parts.append(f\"ì‚¬ìš©ì ë‹µë³€: {a['user_response']}\")\n",
    "    return \"\\n\".join(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCEL ì±„ì  íŒŒì´í”„ë¼ì¸ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCEL ì±„ì  ì²´ì¸\n",
    "grade_chain = (\n",
    "    ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"ì±„ì ê´€ìœ¼ë¡œì„œ ì •ë‹µ íŒë‹¨ ë° í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.\"),\n",
    "            (\"user\", \"{grading_input}\"),\n",
    "        ]\n",
    "    )\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í€´ì¦ˆ ì‹œì‘ ìš”ì²­ ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆ ì‹œì‘ ìš”ì²­ ì²˜ë¦¬\n",
    "def handle_quiz_start(user_input, quiz_state, messages):\n",
    "    quiz_state[\"questions\"] = load_quiz()\n",
    "    quiz_state[\"quiz_index\"] = 0\n",
    "    quiz_state[\"user_answers\"] = []\n",
    "    qtext = get_question(quiz_state)\n",
    "    messages.append([user_input, qtext])\n",
    "    return quiz_state, messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í€´ì¦ˆê°€ ì´ë¯¸ ëë‚œ ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í€´ì¦ˆê°€ ì´ë¯¸ ëë‚œ ê²½ìš°\n",
    "def handle_quiz_already_done(user_input, messages):\n",
    "    messages.append(\n",
    "        [\n",
    "            user_input,\n",
    "            \"í€´ì¦ˆê°€ ì´ë¯¸ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œì‘í•˜ë ¤ë©´ 'í€´ì¦ˆ ì‹œì‘'ì´ë¼ê³  ì…ë ¥í•˜ì„¸ìš”.\",\n",
    "        ]\n",
    "    )\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì‚¬ìš©ì ë‹µë³€ ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©ì ë‹µë³€ ì²˜ë¦¬\n",
    "def handle_user_answer(user_input, quiz_state, messages):\n",
    "    quiz_state = update_state(quiz_state, user_input)\n",
    "\n",
    "    if quiz_state[\"quiz_index\"] < len(quiz_state[\"questions\"]):\n",
    "        qtext = get_question(quiz_state)\n",
    "        messages.append([user_input, qtext])\n",
    "    else:\n",
    "        prompt = build_grading_prompt(quiz_state)\n",
    "        result = grade_chain.invoke({\"grading_input\": prompt})\n",
    "        messages.append([user_input, result])\n",
    "\n",
    "    return quiz_state, messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë©”ì¸ ì±—ë´‡ ì²˜ë¦¬ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©”ì¸ ì±—ë´‡ ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def chat_fn(user_input, state):\n",
    "    user_input_lower = user_input.strip().lower()\n",
    "    messages = state[\"chat_history\"]\n",
    "    quiz_state = state[\"quiz_state\"]\n",
    "\n",
    "    if quiz_state[\"questions\"] == []:\n",
    "        if user_input_lower in [\"í€´ì¦ˆ\", \"í€´ì¦ˆ ì‹œì‘\"]:\n",
    "            quiz_state, messages = handle_quiz_start(user_input, quiz_state, messages)\n",
    "        else:\n",
    "            messages.append(\n",
    "                [\n",
    "                    user_input,\n",
    "                    \"'í€´ì¦ˆ' ë˜ëŠ” 'í€´ì¦ˆ ì‹œì‘'ì´ë¼ê³  ì…ë ¥í•˜ë©´ í€´ì¦ˆë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\",\n",
    "                ]\n",
    "            )\n",
    "    elif quiz_state[\"quiz_index\"] >= len(quiz_state[\"questions\"]):\n",
    "        messages = handle_quiz_already_done(user_input, messages)\n",
    "    else:\n",
    "        quiz_state, messages = handle_user_answer(user_input, quiz_state, messages)\n",
    "\n",
    "    state[\"quiz_state\"] = quiz_state\n",
    "    state[\"chat_history\"] = messages\n",
    "    return messages, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì´ˆê¸° ìƒíƒœ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒíƒœ ì´ˆê¸°í™”\n",
    "def init_state():\n",
    "    return {\n",
    "        \"quiz_state\": {\"quiz_index\": 0, \"questions\": [], \"user_answers\": []},\n",
    "        \"chat_history\": [],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio UI ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## ğŸ•µï¸ ëª…íƒì • ì½”ë‚œ ë§¤ë‹ˆì•„ íŒë³„ê¸°\")\n",
    "    chatbot = gr.Chatbot(label=\"ëª…íƒì • ì½”ë‚œ í€´ì¦ˆ ì±—ë´‡\", height=400)\n",
    "    txt = gr.Textbox(placeholder=\"'í€´ì¦ˆ ì‹œì‘'ì„ ì…ë ¥í•´ë³´ì„¸ìš”!\", show_label=False)\n",
    "    state = gr.State(init_state())\n",
    "\n",
    "    txt.submit(chat_fn, inputs=[txt, state], outputs=[chatbot, state])\n",
    "    txt.submit(lambda: \"\", None, txt)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-t0JhnSEV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
