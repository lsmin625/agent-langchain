{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 명탐정 코난 매니아 판독기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI LLM 준비 및 퀴즈 파일 지정\n",
    "* 환경 변수(`.env` 파일)에서 API Key 로딩\n",
    "* 개발 환경에서는 `gpt-4o-mini` 또는 `gpt-3.5-turbo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import random, json, os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 퀴즈 파일 및 출제 문항 개수 지정\n",
    "QUIZ_FILE = \"conan_quiz.json\"\n",
    "QUIZ_COUNT = 3\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 퀴즈 문항 (`conan_quiz.json`) 로딩\n",
    "- `def load_quiz()` :\tload_quiz라는 이름의 함수를 정의\n",
    "- `with open(QUIZ_FILE, \"r\", encoding=\"utf-8\") as f`: 지정된 경로의 JSON 파일(QUIZ_FILE)을 UTF-8 인코딩 방식으로 읽기 모드(\"r\")로 열고, with 구문을 사용하여 파일 사용 후 자동으로 닫히도록 처리\n",
    "- `all_q = json.load(f)` : JSON 파일 내용을 파싱하여 파이썬 객체(리스트 형태, 퀴즈 문제들)로 변환.\n",
    "- `return random.sample(all_q, QUIZ_COUNT)` :전체 문제 중 QUIZ_COUNT 개수만큼 무작위로 샘플링하여 반환(중복 없이 선택)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 퀴즈 로딩 함수\n",
    "def load_quiz():\n",
    "    with open(QUIZ_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        all_q = json.load(f)\n",
    "    return random.sample(all_q, QUIZ_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 출력 구성\n",
    "퀴즈 상태 정보(`state`)를 기반으로, 현재 문제를 텍스트로 출력해주는 역할로 선다형(`multiple_choice`) 문제에 대해 선택지를 함께 출력하도록 구성\n",
    "- `def get_question(state)` : 퀴즈 상태 객체(`state`)를 받아 현재 문제를 문자열로 구성해 반환하는 함수\n",
    "- `idx = state[\"quiz_index\"]` : 현재 퀴즈 진행 인덱스(첫 번째 문제는 0)\n",
    "- `q = state[\"questions\"][idx]` : 문제 리스트 중 현재 인덱스에 해당하는 문제 데이터 (각 문제는 딕셔너리 구조)\n",
    "- `text = f\"문제 {idx+1}: {q['question']}\"` : 문제 텍스트를 구성 (idx+1로 번호를 1부터 시작하도록 표시) - 예) 문제 1: 코난의 본명은?\n",
    "- `if q[\"type\"] == \"multiple_choice\"` : 현재 문제가 **선다형(`multiple_choice`)**인지 확인\n",
    "- `choices = [f\"{i+1}. {c}\" for i, c in enumerate(q[\"choices\"])]` : 선다형 선택지를 1. 보기 형식으로 나열 - 예) [\"1. 쿠도 신이치\", \"2. 하이바라 아이\", ...]\n",
    "- `text += \"\\n\" + \"\\n\".join(choices)` : 문제 텍스트에 줄바꿈 후 선택지들을 한 줄씩 추가\n",
    "- `return text` : 최종적으로 구성된 문제 문자열을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 출력 - 선다형 구성\n",
    "def get_question(state):\n",
    "    idx = state[\"quiz_index\"]\n",
    "    q = state[\"questions\"][idx]\n",
    "    text = f\"문제 {idx+1}: {q['question']}\"\n",
    "    if q[\"type\"] == \"multiple_choice\":\n",
    "        choices = [f\"{i+1}. {c}\" for i, c in enumerate(q[\"choices\"])]\n",
    "        text += \"\\n\" + \"\\n\".join(choices)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용자 응답 구성\n",
    "사용자의 답변을 현재 상태(`state`)에 저장하고, 퀴즈 인덱스를 다음 문제로 넘기는 역할\n",
    "- 사용자 입력 저장 : 현재 문제에 대한 사용자 응답을 저장\n",
    "- 응답 전처리 : 선다형일 경우 숫자를 선택지 텍스트로 변환\n",
    "- 다음 문제로 진행: `quiz_index`를 1 증가시켜 다음 문제로 이동 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 답변을 상태에 저장\n",
    "def update_state(state, user_input):\n",
    "    idx = state[\"quiz_index\"]\n",
    "    q = state[\"questions\"][idx]\n",
    "    processed = user_input.strip()               # 사용자 입력 앞뒤 공백 제거\n",
    "\n",
    "    if q[\"type\"] == \"multiple_choice\":\n",
    "        try:\n",
    "            sel = int(processed) - 1             # 사용자 입력을 선다형 인덱스로 변환 (1 작은 수)\n",
    "            if 0 <= sel < len(q[\"choices\"]):     # 인덱스 유효 범위 확인\n",
    "                processed = q[\"choices\"][sel]\n",
    "        except:\n",
    "            pass                                 # 입력 상태 유지\n",
    "\n",
    "    state[\"user_answers\"].append(                # 사용자 응답 결과를 기록하는 리스트에 새로운 항목을 추가\n",
    "        {\n",
    "            \"question_text\": q[\"question\"],      # 퀴즈 문항 질문\n",
    "            \"user_response\": processed,          # 사용자 답변\n",
    "            \"is_correct\": False,                 # 정답 여부는 아직 채점 전이므로 일단 False로 저장\n",
    "            \"correct_answer\": str(q[\"answer\"]),  # 정답은 문자열로 변환해서 저장\n",
    "        }\n",
    "    )\n",
    "    state[\"quiz_index\"] += 1                     # 다음 문제로 넘어가기 위해 인덱스를 1 증가\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM으로 보낼 채점 프롬프트\n",
    "LLM에 퀴즈 채점을 위한 프롬프트로 사용자 답변의 정답 여부 및 피드백을 요청할 때 사용\n",
    "- 사용자 응답(`user_answers`)과 문제(`questions`) 정보를 기반으로, 채점 요청 프롬프트를 LLM에게 전달하기 위해 생성\n",
    "- 전체 퀴즈를 하나의 긴 문자열 프롬프트로 반환 (문제 + 정답 + 사용자 답변)\n",
    "- 선다형이면 선택지까지 제공함으로써 LLM이 문맥 기반으로 정확히 판단할 수 있도록 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채점 프롬프트 생성\n",
    "def build_grading_prompt(state):\n",
    "    parts = [\n",
    "        \"당신은 퀴즈 채점관입니다. 사용자 답변을 정답 여부로 판단하고 각 문제에 피드백을 제공해주세요.\",\n",
    "        \"마지막에는 '총점: X/Y' 형식으로 출력해주세요.\",\n",
    "    ]\n",
    "    for i, (q, a) in enumerate(zip(state[\"questions\"], state[\"user_answers\"])):\n",
    "        parts.append(f\"\\n문제 {i+1}: {q['question']}\")\n",
    "        if q[\"type\"] == \"multiple_choice\":\n",
    "            parts.append(f\"선택지: {', '.join(q['choices'])}\")\n",
    "        parts.append(f\"정답: {q['answer']}\")\n",
    "        parts.append(f\"사용자 답변: {a['user_response']}\")\n",
    "    return \"\\n\".join(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCEL 채점 파이프라인 구성\n",
    "LangChain Expression Language(LCEL)를 사용하여 채점용 LLM 체인을 구성\n",
    "- `ChatPromptTemplate.from_messages(...)` : 역할 기반 메시지 형식의 프롬프트를 정의\n",
    "- `(\"user\", \"{grading_input}\")` : 퀴즈 질문과 사용자의 응답을 채점할 내용 (`build_grading_prompt()` 함수로 생성된 프롬프트)\n",
    "- `StrOutputParser()` : LLM의 응답을 문자열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCEL 채점 체인\n",
    "grade_chain = (\n",
    "    ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"채점관으로서 정답 판단 및 피드백을 제공해주세요.\"),\n",
    "            (\"user\", \"{grading_input}\"),\n",
    "        ]\n",
    "    )\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 챗봇 메인 함수 내 - 퀴즈 시작 요청 처리\n",
    "사용자가 \"퀴즈\" 또는 \"퀴즈 시작\"이라고 입력했을 때, 퀴즈를 초기화하고 첫 번째 문제를 메시지에 추가\n",
    "- `quiz_state[\"questions\"] = load_quiz()` : JSON에서 퀴즈 문제를 불러와 `quiz_state` 딕셔너리에 저장\n",
    "- `messages.append([user_input, qtext])` : 사용자 입력과 챗봇 응답을 쌍으로 저장하여 채팅 히스토리를 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 퀴즈 시작 요청 처리\n",
    "def handle_quiz_start(user_input, quiz_state, messages):\n",
    "    quiz_state[\"questions\"] = load_quiz()\n",
    "    quiz_state[\"quiz_index\"] = 0\n",
    "    quiz_state[\"user_answers\"] = []\n",
    "    qtext = get_question(quiz_state)\n",
    "    messages.append([user_input, qtext])\n",
    "    return quiz_state, messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 챗봇 메인 함수 내 - 퀴즈가 이미 끝난 경우\n",
    "퀴즈가 이미 끝났는데도 사용자가 계속 입력할 경우, 안내 메시지를 보냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 퀴즈가 이미 끝난 경우\n",
    "def handle_quiz_already_done(user_input, messages):\n",
    "    messages.append(\n",
    "        [\n",
    "            user_input,\n",
    "            \"퀴즈가 이미 종료되었습니다. 다시 시작하려면 '퀴즈 시작'이라고 입력하세요.\",\n",
    "        ]\n",
    "    )\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 챗봇 메인 함수 내 - 사용자 답변 처리\n",
    "사용자의 답변을 저장하고, 다음 문제를 보여주거나, 모든 문제를 마쳤을 경우 채점을 수행\n",
    "- `if quiz_state[\"quiz_index\"] < len(quiz_state[\"questions\"])` : 현재 퀴즈가 아직 진행 중인지 확인\n",
    "- `prompt = build_grading_prompt(quiz_state)` : 사용자 답변들과 정답을 LLM에게 넘기기 위한 프롬프트(문자열)를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 답변 처리\n",
    "def handle_user_answer(user_input, quiz_state, messages):\n",
    "    quiz_state = update_state(quiz_state, user_input)\n",
    "\n",
    "    if quiz_state[\"quiz_index\"] < len(quiz_state[\"questions\"]):\n",
    "        qtext = get_question(quiz_state)\n",
    "        messages.append([user_input, qtext])\n",
    "    else:\n",
    "        prompt = build_grading_prompt(quiz_state)\n",
    "        result = grade_chain.invoke({\"grading_input\": prompt})\n",
    "        messages.append([user_input, result])\n",
    "\n",
    "    return quiz_state, messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 메인 챗봇 처리 함수\n",
    "챗봇의 메인 제어 함수. 사용자의 입력에 따라 퀴즈를 시작할지, 계속할지, 종료 안내할지를 판단\n",
    "- `user_input_lower = user_input.strip().lower()` : 사용자 입력에서 공백을 제거하고 소문자로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메인 챗봇 처리 함수\n",
    "def chat_fn(user_input, state):\n",
    "    user_input_lower = user_input.strip().lower()\n",
    "    messages = state[\"chat_history\"]\n",
    "    quiz_state = state[\"quiz_state\"]\n",
    "\n",
    "    if quiz_state[\"questions\"] == []:\n",
    "        if user_input_lower in [\"퀴즈\", \"퀴즈 시작\"]:\n",
    "            quiz_state, messages = handle_quiz_start(user_input, quiz_state, messages)\n",
    "        else:\n",
    "            messages.append(\n",
    "                [\n",
    "                    user_input,\n",
    "                    \"'퀴즈' 또는 '퀴즈 시작'이라고 입력하면 퀴즈를 시작합니다.\",\n",
    "                ]\n",
    "            )\n",
    "    elif quiz_state[\"quiz_index\"] >= len(quiz_state[\"questions\"]):\n",
    "        messages = handle_quiz_already_done(user_input, messages)\n",
    "    else:\n",
    "        quiz_state, messages = handle_user_answer(user_input, quiz_state, messages)\n",
    "\n",
    "    state[\"quiz_state\"] = quiz_state\n",
    "    state[\"chat_history\"] = messages\n",
    "    return messages, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 초기 상태 정의\n",
    "퀴즈를 새로 시작하거나 첫 실행 시 사용할 수 있는 초기 상태 딕셔너리를 생성해 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상태 초기화\n",
    "def init_state():\n",
    "    return {\n",
    "        \"quiz_state\": {\"quiz_index\": 0, \"questions\": [], \"user_answers\": []},\n",
    "        \"chat_history\": [],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio UI 정의\n",
    "Gradio의 Blocks UI 구성 방식을 사용해 명탐정 코난 퀴즈 챗봇 인터페이스를 구성\n",
    "- `with gr.Blocks() as demo `: Gradio의 레이아웃 기반 UI 블록을 시작 - 앱 전체 인스턴스를 `demo`로 선언\n",
    "- `gr.Markdown(...)` : 화면 상단에 표시할 설명 문구 (Markdown 문법 사용)\n",
    "- `gr.Chatbot(...)` : 사용자와 AI 간의 대화를 보여주는 대화창 컴포넌트\n",
    "- `gr.Textbox(...)` : 사용자가 입력할 수 있는 텍스트 입력창 (placeholder로 입력 힌트를 표시)\n",
    "- `gr.State(init_state())` : `init_state()`를 호출하여 내부 상태를 저장 - 퀴즈 진행 정보 등을 여기에 보관\n",
    "\n",
    "※ 입력 처리 상세 설명\n",
    "\n",
    "1. `txt.submit(chat_fn, inputs=[txt, state], outputs=[chatbot, state])`\n",
    "    - `txt.submit(...)` : 사용자가 텍스트박스에 입력하고 Enter를 누르면 실행\n",
    "    - `chat_fn` : 메인 처리 함수 - 사용자의 입력을 받아 챗봇 응답과 상태를 계산 또는 \n",
    "    - `inputs=[txt, state]` : 텍스트 입력값과 이전 상태(state)를 chat_fn에 전달\n",
    "    - `outputs=[chatbot, state]` : 함수 결과로 나온 대화 내용과 상태를 챗봇 창과 내부 상태에 각각 반영\n",
    "\n",
    "2. `txt.submit(lambda: \"\", None, txt)`\n",
    "    - `lambda: \"\"` : 아무 동작 없이 빈 문자열을 반환하는 함수\n",
    "    - `None` : 입력값은 없음\n",
    "    - `txt` : 출력 대상은 텍스트박스 자신 - 입력 후 자동으로 입력창을 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### 🕵️ 명탐정 코난 매니아 판별기\")\n",
    "    chatbot = gr.Chatbot(label=\"명탐정 코난 퀴즈 챗봇\", height=400)\n",
    "    txt = gr.Textbox(placeholder=\"'퀴즈 시작'을 입력해보세요!\", show_label=False)\n",
    "    state = gr.State(init_state())\n",
    "\n",
    "    txt.submit(chat_fn, inputs=[txt, state], outputs=[chatbot, state])\n",
    "    txt.submit(lambda: \"\", None, txt)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-t0JhnSEV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
