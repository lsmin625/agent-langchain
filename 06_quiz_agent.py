import gradio as gr
import random, json, os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.agents import initialize_agent, AgentType

# í€´ì¦ˆ íŒŒì¼ ë° ì¶œì œ ë¬¸í•­ ê°œìˆ˜ ì§€ì •
QUIZ_FILE = "data/conan_quiz.json"
QUIZ_COUNT = 3

load_dotenv()
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)


# í€´ì¦ˆ ë¡œë”© í•¨ìˆ˜
def load_quiz():
    with open(QUIZ_FILE, "r", encoding="utf-8") as f:
        all_q = json.load(f)
    return random.sample(all_q, QUIZ_COUNT)


# ë¬¸ì œ ì¶œë ¥ - ì„ ë‹¤í˜• êµ¬ì„±
def get_question(state):
    idx = state["quiz_index"]
    q = state["questions"][idx]
    text = f"ë¬¸ì œ {idx+1}: {q['question']}"
    if q["type"] == "multiple_choice":
        choices = [f"{i+1}. {c}" for i, c in enumerate(q["choices"])]
        text += "\n" + "\n".join(choices)
    return text


# ì‚¬ìš©ì ë‹µë³€ì„ ìƒíƒœì— ì €ì¥
def update_state(state, user_input):
    idx = state["quiz_index"]
    q = state["questions"][idx]
    processed = user_input.strip()  # ì‚¬ìš©ì ì…ë ¥ ì•ë’¤ ê³µë°± ì œê±°

    if q["type"] == "multiple_choice":
        try:
            sel = int(processed) - 1  # ì‚¬ìš©ì ì…ë ¥ì„ ì„ ë‹¤í˜• ì¸ë±ìŠ¤ë¡œ ë³€í™˜ (1 ì‘ì€ ìˆ˜)
            if 0 <= sel < len(q["choices"]):  # ì¸ë±ìŠ¤ ìœ íš¨ ë²”ìœ„ í™•ì¸
                processed = q["choices"][sel]
        except:
            pass  # ì…ë ¥ ìƒíƒœ ìœ ì§€

    state[
        "user_answers"
    ].append(  # ì‚¬ìš©ì ì‘ë‹µ ê²°ê³¼ë¥¼ ê¸°ë¡í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ì— ìƒˆë¡œìš´ í•­ëª©ì„ ì¶”ê°€
        {
            "question_text": q["question"],  # í€´ì¦ˆ ë¬¸í•­ ì§ˆë¬¸
            "user_response": processed,  # ì‚¬ìš©ì ë‹µë³€
            "is_correct": False,  # ì •ë‹µ ì—¬ë¶€ëŠ” ì•„ì§ ì±„ì  ì „ì´ë¯€ë¡œ ì¼ë‹¨ Falseë¡œ ì €ì¥
            "correct_answer": str(q["answer"]),  # ì •ë‹µì€ ë¬¸ìì—´ë¡œ ë³€í™˜í•´ì„œ ì €ì¥
        }
    )
    state["quiz_index"] += 1  # ë‹¤ìŒ ë¬¸ì œë¡œ ë„˜ì–´ê°€ê¸° ìœ„í•´ ì¸ë±ìŠ¤ë¥¼ 1 ì¦ê°€
    return state


# Agentì—ê²Œ ì „ë‹¬í•  ì±„ì  ë°ì´í„° ìƒì„±
def build_grading_input(state):
    parts = [
        "ì, ì´ì œ ì•„ë˜ì˜ ë¬¸ì œì™€ ì •ë‹µ, ê·¸ë¦¬ê³  ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë³´ê³  ì±„ì ì„ ì‹œì‘í•´ì£¼ì„¸ìš”."
    ]
    for i, (q, a) in enumerate(zip(state["questions"], state["user_answers"])):
        parts.append(f"\n--- ë¬¸ì œ {i+1} ---")
        parts.append(f"ë¬¸ì œ: {q['question']}")
        if q["type"] == "multiple_choice":
            parts.append(f"ì„ íƒì§€: {', '.join(q['choices'])}")
        parts.append(f"ì •ë‹µ: {q['answer']}")
        parts.append(f"ì‚¬ìš©ì ë‹µë³€: {a['user_response']}")
    return "\n".join(parts)


# Agentì—ê²Œ ë¶€ì—¬í•  ì—­í•  ë° ì§€ì¹¨ ì •ì˜
agent_kwargs = {
    "system_message": "ë‹¹ì‹ ì€ 'ëª…íƒì • ì½”ë‚œ' í€´ì¦ˆì˜ ì „ë¬¸ ì±„ì ê´€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì œ, ì •ë‹µ, ì‚¬ìš©ì ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ì±„ì í•´ì£¼ì„¸ìš”. ê° ë¬¸ì œì— ëŒ€í•´ ì •ë‹µ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê³  ì¹œì ˆí•œ í•´ì„¤ì„ ë§ë¶™ì—¬ì£¼ì„¸ìš”. ëª¨ë“  ì±„ì ì´ ëë‚˜ë©´, ë§ˆì§€ë§‰ì—ëŠ” 'ì´ì : X/Y' í˜•ì‹ìœ¼ë¡œ ìµœì¢… ì ìˆ˜ë¥¼ ë°˜ë“œì‹œ ìš”ì•½í•´ì„œ ë³´ì—¬ì¤˜ì•¼ í•©ë‹ˆë‹¤."
}

# ì±„ì  Agent ì´ˆê¸°í™”
grading_agent = initialize_agent(
    tools=[],  # ì´ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œëŠ” ì™¸ë¶€ ë„êµ¬ê°€ í•„ìš” ì—†ìŠµë‹ˆë‹¤.
    llm=llm,
    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,
    verbose=True,  # Agentì˜ ì‘ë™ ê³¼ì •ì„ í™•ì¸í•˜ë ¤ë©´ Trueë¡œ ì„¤ì •
    agent_kwargs=agent_kwargs,
    handle_parsing_errors=True,  # íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ ì‹œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€ì²˜í•˜ë„ë¡ ì„¤ì •
)


# í€´ì¦ˆ ì‹œì‘ ìš”ì²­ ì²˜ë¦¬
def handle_quiz_start(user_input, quiz_state, messages):
    quiz_state["questions"] = load_quiz()
    quiz_state["quiz_index"] = 0
    quiz_state["user_answers"] = []
    qtext = get_question(quiz_state)

    messages.append({"role": "user", "content": user_input})
    messages.append({"role": "assistant", "content": qtext})

    return quiz_state, messages


# í€´ì¦ˆê°€ ì´ë¯¸ ëë‚œ ê²½ìš°
def handle_quiz_already_done(user_input, messages):
    bot_message = (
        "í€´ì¦ˆê°€ ì´ë¯¸ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œì‘í•˜ë ¤ë©´ 'í€´ì¦ˆ ì‹œì‘'ì´ë¼ê³  ì…ë ¥í•˜ì„¸ìš”."
    )

    messages.append({"role": "user", "content": user_input})
    messages.append({"role": "assistant", "content": bot_message})

    return messages


# ì‚¬ìš©ì ë‹µë³€ ì²˜ë¦¬
def handle_user_answer(user_input, quiz_state, messages):
    quiz_state = update_state(quiz_state, user_input)

    messages.append({"role": "user", "content": user_input})

    if quiz_state["quiz_index"] < len(quiz_state["questions"]):
        # ë‹¤ìŒ ë¬¸ì œê°€ ë‚¨ì€ ê²½ìš°
        qtext = get_question(quiz_state)
        messages.append({"role": "assistant", "content": qtext})
    else:
        # ëª¨ë“  ë¬¸ì œë¥¼ í‘¼ ê²½ìš°, ì±„ì  Agent í˜¸ì¶œ
        grading_input_data = build_grading_input(quiz_state)

        # Agent í˜¸ì¶œ
        raw_result = grading_agent.invoke(
            {"input": grading_input_data, "chat_history": []}
        )["output"]

        # [ìˆ˜ì •ëœ ë¶€ë¶„] Agentê°€ ë°˜í™˜í•œ ë”•ì…”ë„ˆë¦¬(ë˜ëŠ” JSON ë¬¸ìì—´)ë¥¼
        # ì‚¬ìš©ìê°€ ë³´ê¸° ì¢‹ì€ í˜•íƒœì˜ ë‹¨ì¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        try:
            # ê²°ê³¼ê°€ JSON ë¬¸ìì—´ì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ íŒŒì‹± ì‹œë„
            if isinstance(raw_result, str):
                result_data = json.loads(raw_result)
            else:
                result_data = raw_result  # ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°

            # ì±„ì  ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¬¸ìì—´ ë³´ê³ ì„œ ìƒì„±
            report_parts = ["ì±„ì ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ“\n"]
            for i, res in enumerate(result_data.get("results", [])):
                is_correct_text = "ì •ë‹µ" if res.get("is_correct") else "ì˜¤ë‹µ"
                report_parts.append(f"--- ë¬¸ì œ {i+1} ---")
                report_parts.append(f"ë¬¸ì œ: {res.get('question', 'ì§ˆë¬¸ ì—†ìŒ')}")
                report_parts.append(f"ì •ë‹µ: {res.get('correct_answer', 'ì •ë‹µ ì—†ìŒ')}")
                report_parts.append(
                    f"ì œì¶œí•œ ë‹µë³€: {res.get('user_answer', 'ë‹µë³€ ì—†ìŒ')}"
                )
                report_parts.append(f"ê²°ê³¼: {is_correct_text}")
                report_parts.append(f"í•´ì„¤: {res.get('explanation', '')}\n")

            report_parts.append(
                f"**ì´ì : {result_data.get('total_score', 'ì ìˆ˜ ì—†ìŒ')}**"
            )
            final_report = "\n".join(report_parts)

        except (json.JSONDecodeError, TypeError, AttributeError):
            # ë§Œì•½ ê²°ê³¼ê°€ ì˜ˆìƒëœ ë”•ì…”ë„ˆë¦¬ í˜•ì‹ì´ ì•„ë‹ˆë©´, ë°›ì€ ê·¸ëŒ€ë¡œ ì¶œë ¥
            final_report = str(raw_result)

        messages.append({"role": "assistant", "content": final_report})

    return quiz_state, messages


# ë©”ì¸ ì±—ë´‡ ì²˜ë¦¬ í•¨ìˆ˜
def chat_fn(user_input, state):
    user_input_lower = user_input.strip().lower()
    messages = state["chat_history"]
    quiz_state = state["quiz_state"]

    if not quiz_state["questions"]:
        if user_input_lower in ["í€´ì¦ˆ", "í€´ì¦ˆ ì‹œì‘"]:
            quiz_state, messages = handle_quiz_start(user_input, quiz_state, messages)
        else:
            bot_message = "'í€´ì¦ˆ' ë˜ëŠ” 'í€´ì¦ˆ ì‹œì‘'ì´ë¼ê³  ì…ë ¥í•˜ë©´ í€´ì¦ˆë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."
            messages.append({"role": "user", "content": user_input})
            messages.append({"role": "assistant", "content": bot_message})

    elif quiz_state["quiz_index"] >= len(quiz_state["questions"]):
        messages = handle_quiz_already_done(user_input, messages)
    else:
        quiz_state, messages = handle_user_answer(user_input, quiz_state, messages)

    state["quiz_state"] = quiz_state
    state["chat_history"] = messages
    return messages, state


# ìƒíƒœ ì´ˆê¸°í™”
def init_state():
    return {
        "quiz_state": {"quiz_index": 0, "questions": [], "user_answers": []},
        "chat_history": [],
    }


# Gradio UI
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("### ğŸ•µï¸ ëª…íƒì • ì½”ë‚œ ë§¤ë‹ˆì•„ íŒë³„ê¸°")

    chatbot = gr.Chatbot(
        label="ëª…íƒì • ì½”ë‚œ í€´ì¦ˆ ì±—ë´‡",
        height=400,
        avatar_images=("data/avatar_user.png", "data/avatar_conan.png"),
        type="messages",
    )

    txt = gr.Textbox(placeholder="'í€´ì¦ˆ ì‹œì‘'ì„ ì…ë ¥í•´ë³´ì„¸ìš”!", show_label=False)
    state = gr.State(init_state())

    txt.submit(chat_fn, inputs=[txt, state], outputs=[chatbot, state])
    txt.submit(lambda: "", None, txt)

demo.launch()
