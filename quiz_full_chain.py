import gradio as gr
import random, json, os
from dotenv import load_dotenv
from typing import List, TypedDict

# LangChain ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from langchain_openai import ChatOpenAI
from langchain_core.prompts import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from pydantic import BaseModel, Field
from langchain_core.output_parsers import PydanticOutputParser
from langgraph.graph import StateGraph, END

QUIZ_FILE = "data/conan_quiz.json"
QUIZ_COUNT = 3

load_dotenv()
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)


def load_quiz():
    if not os.path.exists("data"):
        os.makedirs("data")
    if not os.path.exists(QUIZ_FILE):
        default_quiz = [
            {
                "type": "short_answer",
                "question": "ì½”ë‚œì˜ ë³¸ëª…ì€ ë¬´ì—‡ì¼ê¹Œìš”?",
                "answer": "ì¿ ë„ ì‹ ì´ì¹˜",
            },
            {
                "type": "multiple_choice",
                "question": "ì½”ë‚œì„ ì‘ì•„ì§€ê²Œ ë§Œë“  ì•½ì˜ ì´ë¦„ì€?",
                "choices": ["APTX4869", "APTX4868", "APTX4870"],
                "answer": "APTX4869",
            },
            {
                "type": "short_answer",
                "question": "ë€ì˜ ì•„ë²„ì§€ëŠ” ì§ì—…ì€ ë¬´ì—‡ì¼ê¹Œìš”?",
                "answer": "íƒì •",
            },
        ]
        with open(QUIZ_FILE, "w", encoding="utf-8") as f:
            json.dump(default_quiz, f, ensure_ascii=False, indent=2)
    with open(QUIZ_FILE, "r", encoding="utf-8") as f:
        all_q = json.load(f)
    count = min(QUIZ_COUNT, len(all_q))
    return random.sample(all_q, count)


class GradingResult(BaseModel):
    question: str = Field(description="ì±„ì  ëŒ€ìƒ ë¬¸ì œ")
    correct_answer: str = Field(description="ë¬¸ì œì˜ ì •ë‹µ")
    user_answer: str = Field(description="ì‚¬ìš©ìê°€ ì œì¶œí•œ ë‹µë³€")
    is_correct: bool = Field(description="ì •ë‹µ ì—¬ë¶€")
    explanation: str = Field(description="ì •ë‹µì— ëŒ€í•œ ì¹œì ˆí•œ í•´ì„¤")


class FinalReport(BaseModel):
    results: List[GradingResult] = Field(description="ê° ë¬¸ì œë³„ ì±„ì  ê²°ê³¼ ë¦¬ìŠ¤íŠ¸")
    total_score: str = Field(description="'ì´ì : X/Y' í˜•ì‹ì˜ ìµœì¢… ì ìˆ˜ ìš”ì•½")


class GradingState(TypedDict):
    grading_input: str
    final_report: FinalReport


def grade_quiz(state: GradingState):
    parser = PydanticOutputParser(pydantic_object=FinalReport)
    system_message = "ë‹¹ì‹ ì€ 'ëª…íƒì • ì½”ë‚œ' í€´ì¦ˆì˜ ì „ë¬¸ ì±„ì ê´€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì œ, ì •ë‹µ, ì‚¬ìš©ì ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ì±„ì í•´ì£¼ì„¸ìš”. ê° ë¬¸ì œì— ëŒ€í•´ ì •ë‹µ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê³  ì¹œì ˆí•œ í•´ì„¤ì„ ë§ë¶™ì—¬ì£¼ì„¸ìš”. ëª¨ë“  ì±„ì ì´ ëë‚˜ë©´, ë§ˆì§€ë§‰ì—ëŠ” 'ì´ì : X/Y' í˜•ì‹ìœ¼ë¡œ ìµœì¢… ì ìˆ˜ë¥¼ ë°˜ë“œì‹œ ìš”ì•½í•´ì„œ ë³´ì—¬ì¤˜ì•¼ í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ ì§€ì •ëœ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤."
    prompt = ChatPromptTemplate(
        messages=[
            SystemMessagePromptTemplate.from_template(system_message),
            HumanMessagePromptTemplate.from_template(
                "{grading_data}\n\n{format_instructions}"
            ),
        ],
        input_variables=["grading_data"],
        partial_variables={"format_instructions": parser.get_format_instructions()},
    )
    chain = prompt | llm | parser
    try:
        report = chain.invoke({"grading_data": state["grading_input"]})
        return {"final_report": report}
    except Exception as e:
        print(f"ì±„ì  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        error_report = FinalReport(results=[], total_score="ì±„ì  ì˜¤ë¥˜")
        return {"final_report": error_report}


workflow = StateGraph(GradingState)
workflow.add_node("grader", grade_quiz)
workflow.set_entry_point("grader")
workflow.add_edge("grader", END)
grading_app = workflow.compile()


def get_question(state):
    idx = state["quiz_index"]
    q = state["questions"][idx]
    text = f"ë¬¸ì œ {idx+1}: {q['question']}"
    if q["type"] == "multiple_choice":
        choices = [f"{i+1}. {c}" for i, c in enumerate(q["choices"])]
        text += "\n" + "\n".join(choices)
    return text


def update_state(state, user_input):
    idx = state["quiz_index"]
    q = state["questions"][idx]
    processed = user_input.strip()
    if q["type"] == "multiple_choice":
        try:
            sel = int(processed) - 1
            if 0 <= sel < len(q["choices"]):
                processed = q["choices"][sel]
        except (ValueError, IndexError):
            pass
    state["user_answers"].append({"user_response": processed})
    state["quiz_index"] += 1
    return state


def build_grading_input(state):
    parts = [
        "ì, ì´ì œ ì•„ë˜ì˜ ë¬¸ì œì™€ ì •ë‹µ, ê·¸ë¦¬ê³  ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë³´ê³  ì±„ì ì„ ì‹œì‘í•´ì£¼ì„¸ìš”."
    ]
    for i, (q, a) in enumerate(zip(state["questions"], state["user_answers"])):
        parts.append(f"\n--- ë¬¸ì œ {i+1} ---")
        parts.append(f"ë¬¸ì œ: {q['question']}")
        if q["type"] == "multiple_choice":
            parts.append(f"ì„ íƒì§€: {', '.join(q['choices'])}")
        parts.append(f"ì •ë‹µ: {q['answer']}")
        parts.append(f"ì‚¬ìš©ì ë‹µë³€: {a['user_response']}")
    return "\n".join(parts)


def handle_quiz_start(user_input, quiz_state, messages):
    quiz_state["questions"] = load_quiz()
    if not quiz_state["questions"]:
        messages.append(("user", user_input))
        messages.append(
            ("assistant", "í€´ì¦ˆë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆê±°ë‚˜ í’€ ìˆ˜ ìˆëŠ” ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.")
        )
        return quiz_state, messages
    quiz_state["quiz_index"] = 0
    quiz_state["user_answers"] = []
    qtext = get_question(quiz_state)
    messages.append(("user", user_input))
    messages.append(("assistant", qtext))
    return quiz_state, messages


def handle_quiz_already_done(user_input, messages):
    bot_message = "í€´ì¦ˆê°€ ì´ë¯¸ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. í€´ì¦ˆë¥¼ ë‹¤ì‹œ ì‹œì‘í•˜ë ¤ë©´ 'í€´ì¦ˆ ì‹œì‘'ì´ë¼ê³  ì…ë ¥í•´ì£¼ì„¸ìš”."
    messages.append(("user", user_input))
    messages.append(("assistant", bot_message))
    return messages


def handle_user_answer(user_input, quiz_state, messages):
    quiz_state = update_state(quiz_state, user_input)
    messages.append(("user", user_input))
    if quiz_state["quiz_index"] < len(quiz_state["questions"]):
        qtext = get_question(quiz_state)
        messages.append(("assistant", qtext))
    else:
        grading_input_data = build_grading_input(quiz_state)
        result_state = grading_app.invoke({"grading_input": grading_input_data})
        final_report_obj = result_state["final_report"]
        report_parts = ["ì±„ì ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ“\n"]
        if final_report_obj and final_report_obj.results:
            for i, res in enumerate(final_report_obj.results):
                is_correct_text = "ì •ë‹µ" if res.is_correct else "ì˜¤ë‹µ"
                report_parts.append(f"--- ë¬¸ì œ {i+1} ---")
                report_parts.append(f"ë¬¸ì œ: {res.question}")
                report_parts.append(f"ì •ë‹µ: {res.correct_answer}")
                report_parts.append(f"ì œì¶œí•œ ë‹µë³€: {res.user_answer}")
                report_parts.append(f"ê²°ê³¼: {is_correct_text}")
                report_parts.append(f"í•´ì„¤: {res.explanation}\n")
            report_parts.append(f"**{final_report_obj.total_score}**")
        else:
            report_parts.append("ì±„ì  ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        final_report_str = "\n".join(report_parts)
        messages.append(("assistant", final_report_str))
    return quiz_state, messages


def chat_fn(user_input, state):
    messages = state["chat_history"].copy()
    quiz_state = state["quiz_state"]
    user_input_lower = user_input.strip().lower()

    # í€´ì¦ˆ ìƒíƒœì— ë”°ë¥¸ ë¶„ê¸° ë¡œì§
    if not quiz_state.get("questions") or not quiz_state.get("questions"):
        if user_input_lower in ["í€´ì¦ˆ", "í€´ì¦ˆ ì‹œì‘"]:
            quiz_state, messages = handle_quiz_start(user_input, quiz_state, messages)
        else:
            bot_message = "'í€´ì¦ˆ' ë˜ëŠ” 'í€´ì¦ˆ ì‹œì‘'ì´ë¼ê³  ì…ë ¥í•˜ë©´ í€´ì¦ˆë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."
            messages.append(("user", user_input))
            messages.append(("assistant", bot_message))
    elif quiz_state["quiz_index"] >= len(quiz_state["questions"]):
        if user_input_lower in ["í€´ì¦ˆ", "í€´ì¦ˆ ì‹œì‘"]:
            quiz_state, messages = handle_quiz_start(user_input, quiz_state, messages)
        else:
            messages = handle_quiz_already_done(user_input, messages)
    else:
        quiz_state, messages = handle_user_answer(user_input, quiz_state, messages)

    # state ì—…ë°ì´íŠ¸
    state["quiz_state"] = quiz_state
    state["chat_history"] = messages

    # ### Gradio ì±—ë´‡ì˜ 'value' í˜•ì‹ ë³€í™˜ ###
    # ë‚´ë¶€ ë©”ì‹œì§€ í˜•ì‹ [('user', ...), ('assistant', ...)]ì„
    # ìƒˆë¡œìš´ í‘œì¤€ í˜•ì‹ [{'role': 'user', 'content': ...}, {'role': 'assistant', 'content': ...}]ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    chat_display = []
    for role, content in messages:
        chat_display.append({"role": role, "content": content})

    return chat_display, state


def init_state():
    return {
        "quiz_state": {"quiz_index": 0, "questions": [], "user_answers": []},
        "chat_history": [],
    }


# --- UI ì •ì˜ ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("### ğŸ•µï¸ ëª…íƒì • ì½”ë‚œ ë§¤ë‹ˆì•„ íŒë³„ê¸° (LangGraph ver.)")

    chatbot = gr.Chatbot(
        label="ëª…íƒì • ì½”ë‚œ í€´ì¦ˆ ì±—ë´‡",
        height=500,
        avatar_images=("data/avatar_user.png", "data/avatar_conan.png"),
        type="messages",
    )

    txt = gr.Textbox(
        placeholder="'í€´ì¦ˆ ì‹œì‘'ì„ ì…ë ¥í•´ë³´ì„¸ìš”!", show_label=False, container=False
    )
    state = gr.State(init_state())
    txt.submit(chat_fn, inputs=[txt, state], outputs=[chatbot, state])
    txt.submit(lambda: "", None, txt, queue=False)

demo.launch(debug=True)
