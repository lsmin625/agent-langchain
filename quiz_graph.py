import gradio as gr
import random, json, os
from dotenv import load_dotenv
from typing import List, TypedDict

# LangChain ë° LangGraph ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from langchain_openai import ChatOpenAI
from langchain_core.prompts import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.output_parsers import PydanticOutputParser
from langgraph.graph import StateGraph, END

# --- ê¸°ë³¸ ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼) ---
# í€´ì¦ˆ íŒŒì¼ ë° ì¶œì œ ë¬¸í•­ ê°œìˆ˜ ì§€ì •
QUIZ_FILE = "data/conan_quiz.json"
QUIZ_COUNT = 3

load_dotenv()
# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)


# --- LangGraph ì±„ì  ì—ì´ì „íŠ¸ ì •ì˜ ---


# 1. ì±„ì  ê²°ê³¼ì˜ ë°ì´í„° êµ¬ì¡°ë¥¼ Pydanticìœ¼ë¡œ ì •ì˜
class GradingResult(BaseModel):
    """ë‹¨ì¼ ë¬¸ì œì— ëŒ€í•œ ì±„ì  ê²°ê³¼"""

    question: str = Field(description="ì±„ì  ëŒ€ìƒ ë¬¸ì œ")
    correct_answer: str = Field(description="ë¬¸ì œì˜ ì •ë‹µ")
    user_answer: str = Field(description="ì‚¬ìš©ìê°€ ì œì¶œí•œ ë‹µë³€")
    is_correct: bool = Field(description="ì •ë‹µ ì—¬ë¶€")
    explanation: str = Field(description="ì •ë‹µì— ëŒ€í•œ ì¹œì ˆí•œ í•´ì„¤")


class FinalReport(BaseModel):
    """ëª¨ë“  ë¬¸ì œì— ëŒ€í•œ ìµœì¢… ì±„ì  ë³´ê³ ì„œ"""

    results: List[GradingResult] = Field(description="ê° ë¬¸ì œë³„ ì±„ì  ê²°ê³¼ ë¦¬ìŠ¤íŠ¸")
    total_score: str = Field(description="'ì´ì : X/Y' í˜•ì‹ì˜ ìµœì¢… ì ìˆ˜ ìš”ì•½")


# 2. LangGraphì˜ ìƒíƒœ(State) ì •ì˜
class GradingState(TypedDict):
    grading_input: str  # ì±„ì ì„ ìœ„í•´ LLMì— ì „ë‹¬ë  ì „ì²´ í…ìŠ¤íŠ¸
    final_report: FinalReport  # LLMì´ ìƒì„±í•œ êµ¬ì¡°í™”ëœ ì±„ì  ê²°ê³¼


# 3. ì±„ì  ë¡œì§ì„ ìˆ˜í–‰í•  ë…¸ë“œ(Node) í•¨ìˆ˜ ì •ì˜
def grade_quiz(state: GradingState):
    """
    ì…ë ¥ëœ í€´ì¦ˆ ë°ì´í„°ì— ëŒ€í•´ LLMì„ í˜¸ì¶œí•˜ì—¬ ì±„ì í•˜ê³  ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    # Pydantic ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì¶œë ¥ íŒŒì„œ ìƒì„±
    parser = PydanticOutputParser(pydantic_object=FinalReport)

    # LLMì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
    system_message = "ë‹¹ì‹ ì€ 'ëª…íƒì • ì½”ë‚œ' í€´ì¦ˆì˜ ì „ë¬¸ ì±„ì ê´€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì œ, ì •ë‹µ, ì‚¬ìš©ì ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ì±„ì í•´ì£¼ì„¸ìš”. ê° ë¬¸ì œì— ëŒ€í•´ ì •ë‹µ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê³  ì¹œì ˆí•œ í•´ì„¤ì„ ë§ë¶™ì—¬ì£¼ì„¸ìš”. ëª¨ë“  ì±„ì ì´ ëë‚˜ë©´, ë§ˆì§€ë§‰ì—ëŠ” 'ì´ì : X/Y' í˜•ì‹ìœ¼ë¡œ ìµœì¢… ì ìˆ˜ë¥¼ ë°˜ë“œì‹œ ìš”ì•½í•´ì„œ ë³´ì—¬ì¤˜ì•¼ í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ ì§€ì •ëœ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤."
    prompt = ChatPromptTemplate(
        messages=[
            SystemMessagePromptTemplate.from_template(system_message),
            HumanMessagePromptTemplate.from_template(
                "{grading_data}\n\n{format_instructions}"
            ),
        ],
        input_variables=["grading_data"],
        partial_variables={"format_instructions": parser.get_format_instructions()},
    )

    # í”„ë¡¬í”„íŠ¸, LLM, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°í•˜ì—¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ì²´ì¸(Runnable) ìƒì„±
    chain = prompt | llm | parser

    # ì²´ì¸ ì‹¤í–‰
    report = chain.invoke({"grading_data": state["grading_input"]})

    # ê³„ì‚°ëœ ê²°ê³¼ë¥¼ ìƒíƒœì— ì—…ë°ì´íŠ¸í•˜ì—¬ ë°˜í™˜
    return {"final_report": report}


# 4. ê·¸ë˜í”„(Graph) ìƒì„± ë° ì»´íŒŒì¼
workflow = StateGraph(GradingState)
workflow.add_node("grader", grade_quiz)  # ë…¸ë“œ ì¶”ê°€
workflow.set_entry_point("grader")  # ì‹œì‘ì  ì„¤ì •
workflow.add_edge("grader", END)  # ë…¸ë“œ ì‹¤í–‰ í›„ ì¢…ë£Œ
grading_app = workflow.compile()  # ì‹¤í–‰ ê°€ëŠ¥í•œ ì•±ìœ¼ë¡œ ì»´íŒŒì¼


# --- í€´ì¦ˆ ë¡œì§ ë° Gradio UI (ëŒ€ë¶€ë¶„ ê¸°ì¡´ê³¼ ë™ì¼) ---


# í€´ì¦ˆ ë¡œë”© í•¨ìˆ˜
def load_quiz():
    with open(QUIZ_FILE, "r", encoding="utf-8") as f:
        all_q = json.load(f)
    return random.sample(all_q, QUIZ_COUNT)


# ë¬¸ì œ ì¶œë ¥ - ì„ ë‹¤í˜• êµ¬ì„±
def get_question(state):
    idx = state["quiz_index"]
    q = state["questions"][idx]
    text = f"ë¬¸ì œ {idx+1}: {q['question']}"
    if q["type"] == "multiple_choice":
        choices = [f"{i+1}. {c}" for i, c in enumerate(q["choices"])]
        text += "\n" + "\n".join(choices)
    return text


# ì‚¬ìš©ì ë‹µë³€ì„ ìƒíƒœì— ì €ì¥
def update_state(state, user_input):
    idx = state["quiz_index"]
    q = state["questions"][idx]
    processed = user_input.strip()

    if q["type"] == "multiple_choice":
        try:
            sel = int(processed) - 1
            if 0 <= sel < len(q["choices"]):
                processed = q["choices"][sel]
        except:
            pass

    state["user_answers"].append(
        {
            "question_text": q["question"],
            "user_response": processed,
            "is_correct": False,
            "correct_answer": str(q["answer"]),
        }
    )
    state["quiz_index"] += 1
    return state


# LangGraph Agentì—ê²Œ ì „ë‹¬í•  ì±„ì  ë°ì´í„° ìƒì„±
def build_grading_input(state):
    parts = [
        "ì, ì´ì œ ì•„ë˜ì˜ ë¬¸ì œì™€ ì •ë‹µ, ê·¸ë¦¬ê³  ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë³´ê³  ì±„ì ì„ ì‹œì‘í•´ì£¼ì„¸ìš”."
    ]
    for i, (q, a) in enumerate(zip(state["questions"], state["user_answers"])):
        parts.append(f"\n--- ë¬¸ì œ {i+1} ---")
        parts.append(f"ë¬¸ì œ: {q['question']}")
        if q["type"] == "multiple_choice":
            parts.append(f"ì„ íƒì§€: {', '.join(q['choices'])}")
        parts.append(f"ì •ë‹µ: {q['answer']}")
        parts.append(f"ì‚¬ìš©ì ë‹µë³€: {a['user_response']}")
    return "\n".join(parts)


# í€´ì¦ˆ ì‹œì‘ ìš”ì²­ ì²˜ë¦¬
def handle_quiz_start(user_input, quiz_state, messages):
    quiz_state["questions"] = load_quiz()
    quiz_state["quiz_index"] = 0
    quiz_state["user_answers"] = []
    qtext = get_question(quiz_state)

    messages.append({"role": "user", "content": user_input})
    messages.append({"role": "assistant", "content": qtext})

    return quiz_state, messages


# í€´ì¦ˆê°€ ì´ë¯¸ ëë‚œ ê²½ìš°
def handle_quiz_already_done(user_input, messages):
    bot_message = (
        "í€´ì¦ˆê°€ ì´ë¯¸ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œì‘í•˜ë ¤ë©´ 'í€´ì¦ˆ ì‹œì‘'ì´ë¼ê³  ì…ë ¥í•˜ì„¸ìš”."
    )
    messages.append({"role": "user", "content": user_input})
    messages.append({"role": "assistant", "content": bot_message})
    return messages


# ì‚¬ìš©ì ë‹µë³€ ì²˜ë¦¬
def handle_user_answer(user_input, quiz_state, messages):
    quiz_state = update_state(quiz_state, user_input)
    messages.append({"role": "user", "content": user_input})

    if quiz_state["quiz_index"] < len(quiz_state["questions"]):
        # ë‹¤ìŒ ë¬¸ì œê°€ ë‚¨ì€ ê²½ìš°
        qtext = get_question(quiz_state)
        messages.append({"role": "assistant", "content": qtext})
    else:
        # ëª¨ë“  ë¬¸ì œë¥¼ í‘¼ ê²½ìš°, ì±„ì  Agent í˜¸ì¶œ
        grading_input_data = build_grading_input(quiz_state)

        # [ìˆ˜ì •ëœ ë¶€ë¶„] LangGraph Agent í˜¸ì¶œ
        # ì…ë ¥ìœ¼ë¡œ ìƒíƒœ ë”•ì…”ë„ˆë¦¬ë¥¼ ì „ë‹¬
        result_state = grading_app.invoke({"grading_input": grading_input_data})
        # ê²°ê³¼ëŠ” ìƒíƒœ ë”•ì…”ë„ˆë¦¬ì˜ 'final_report' í‚¤ì— ì €ì¥ë¨ (Pydantic ê°ì²´)
        final_report_obj = result_state["final_report"]

        # Pydantic ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìê°€ ë³´ê¸° ì¢‹ì€ í˜•íƒœì˜ ë¬¸ìì—´ë¡œ ë³€í™˜
        report_parts = ["ì±„ì ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ“\n"]
        for i, res in enumerate(final_report_obj.results):
            is_correct_text = "ì •ë‹µ" if res.is_correct else "ì˜¤ë‹µ"
            report_parts.append(f"--- ë¬¸ì œ {i+1} ---")
            report_parts.append(f"ë¬¸ì œ: {res.question}")
            report_parts.append(f"ì •ë‹µ: {res.correct_answer}")
            report_parts.append(f"ì œì¶œí•œ ë‹µë³€: {res.user_answer}")
            report_parts.append(f"ê²°ê³¼: {is_correct_text}")
            report_parts.append(f"í•´ì„¤: {res.explanation}\n")

        report_parts.append(f"**{final_report_obj.total_score}**")
        final_report_str = "\n".join(report_parts)

        messages.append({"role": "assistant", "content": final_report_str})

    return quiz_state, messages


# ë©”ì¸ ì±—ë´‡ ì²˜ë¦¬ í•¨ìˆ˜
def chat_fn(user_input, state):
    user_input_lower = user_input.strip().lower()
    messages = state["chat_history"]
    quiz_state = state["quiz_state"]

    if not quiz_state["questions"]:
        if user_input_lower in ["í€´ì¦ˆ", "í€´ì¦ˆ ì‹œì‘"]:
            quiz_state, messages = handle_quiz_start(user_input, quiz_state, messages)
        else:
            bot_message = "'í€´ì¦ˆ' ë˜ëŠ” 'í€´ì¦ˆ ì‹œì‘'ì´ë¼ê³  ì…ë ¥í•˜ë©´ í€´ì¦ˆë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."
            messages.append({"role": "user", "content": user_input})
            messages.append({"role": "assistant", "content": bot_message})

    elif quiz_state["quiz_index"] >= len(quiz_state["questions"]):
        messages = handle_quiz_already_done(user_input, messages)
    else:
        quiz_state, messages = handle_user_answer(user_input, quiz_state, messages)

    state["quiz_state"] = quiz_state
    state["chat_history"] = messages
    return messages, state


# ìƒíƒœ ì´ˆê¸°í™”
def init_state():
    return {
        "quiz_state": {"quiz_index": 0, "questions": [], "user_answers": []},
        "chat_history": [],
    }


# Gradio UI
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("### ğŸ•µï¸ ëª…íƒì • ì½”ë‚œ ë§¤ë‹ˆì•„ íŒë³„ê¸° (LangGraph ver.)")
    chatbot = gr.Chatbot(
        label="ëª…íƒì • ì½”ë‚œ í€´ì¦ˆ ì±—ë´‡",
        height=400,
        avatar_images=("data/avatar_user.png", "data/avatar_conan.png"),
        render=False,  # type ëŒ€ì‹  render=False ì‚¬ìš©
    )
    # render=Falseì™€ í•¨ê»˜ Chatbot.like ì‚¬ìš©ì„ ìœ„í•´ ì•„ë˜ì™€ ê°™ì´ ìˆ˜ì •
    chatbot.likeable = True
    chatbot.render()

    txt = gr.Textbox(placeholder="'í€´ì¦ˆ ì‹œì‘'ì„ ì…ë ¥í•´ë³´ì„¸ìš”!", show_label=False)
    state = gr.State(init_state())

    txt.submit(chat_fn, inputs=[txt, state], outputs=[chatbot, state])
    txt.submit(lambda: "", None, txt)

demo.launch()
